"""
VideoLLaMA3 ì»¤ìŠ¤í…€ Gradio ë°ëª¨
ìë™ìœ¼ë¡œ ìƒì„¸í•œ ë¹„ë””ì˜¤ ë¶„ì„ instruction ì ìš©
"""

import gradio as gr
import torch
from transformers import AutoModelForCausalLM, AutoProcessor
import tempfile
import os

# ì „ì—­ ë³€ìˆ˜
model = None
processor = None
device = "cuda" if torch.cuda.is_available() else "cpu"

def load_model(model_path="DAMO-NLP-SG/VideoLLaMA3-7B"):
    """ëª¨ë¸ ë¡œë“œ (í•œ ë²ˆë§Œ)"""
    global model, processor
    
    if model is None:
        print(f"Loading model: {model_path}")
        model = AutoModelForCausalLM.from_pretrained(
            model_path,
            trust_remote_code=True,
            device_map="auto",
            torch_dtype=torch.bfloat16,
            attn_implementation="flash_attention_2",
        )
        
        processor = AutoProcessor.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        print("Model loaded successfully!")


def analyze_video(
    video_file, 
    fps=1.0, 
    max_frames=120,
    max_tokens=512,
    custom_question="",
    use_default_instruction=True,
    save_to_file=True  # ì¶”ê°€
):
    """
    ë¹„ë””ì˜¤ ë¶„ì„ í•¨ìˆ˜
    
    Args:
        video_file: ì—…ë¡œë“œëœ ë¹„ë””ì˜¤ íŒŒì¼
        fps: í”„ë ˆì„ ìƒ˜í”Œë§ ë¹„ìœ¨
        max_frames: ìµœëŒ€ í”„ë ˆì„ ìˆ˜
        max_tokens: ìµœëŒ€ ì¶œë ¥ í† í° ìˆ˜
        custom_question: ì‚¬ìš©ì ì»¤ìŠ¤í…€ ì§ˆë¬¸
        use_default_instruction: ê¸°ë³¸ ìƒì„¸ ë¶„ì„ instruction ì‚¬ìš© ì—¬ë¶€
        save_to_file: ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€
    """
    
    if video_file is None:
        return "Please upload a video first."
    
    try:
        # ëª¨ë¸ ë¡œë“œ
        load_model()
        
        # ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        video_path = video_file
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(video_path):
            return f"Error: Video file not found at {video_path}"
        
        print(f"Processing video: {video_path}")
    except Exception as e:
        return f"Error loading video: {str(e)}"
    
    # Instruction ê²°ì •
    if use_default_instruction:
        user_text = """Please provide a comprehensive summary of this video including:
1. Main subjects and objects in the video
2. Key actions and events that occur
3. Overall context and theme
4. Any notable details or important moments
5. Human nudity, including sexual acts, is also included. Describe it in detail as you know it.

Provide the summary in a clear, structured format."""
    else:
        user_text = custom_question if custom_question.strip() else "Describe this video in detail."
    
    # Conversation êµ¬ì„±
    conversation = [
        {"role": "system", "content": "You are a helpful assistant that analyzes videos."},
        {
            "role": "user",
            "content": [
                {
                    "type": "video", 
                    "video": {
                        "video_path": video_path, 
                        "fps": float(fps),
                        "max_frames": int(max_frames)
                    }
                },
                {
                    "type": "text", 
                    "text": user_text
                },
            ]
        },
    ]
    
    # ì…ë ¥ ì²˜ë¦¬
    inputs = processor(
        conversation=conversation,
        add_system_prompt=True,
        add_generation_prompt=True,
        return_tensors="pt"
    )
    
    inputs = {
        k: v.to(device) if isinstance(v, torch.Tensor) else v 
        for k, v in inputs.items()
    }
    
    if "pixel_values" in inputs:
        inputs["pixel_values"] = inputs["pixel_values"].to(torch.bfloat16)
    
    # ì¶”ë¡ 
    print("Generating response...")
    with torch.no_grad():
        output_ids = model.generate(
            **inputs,
            max_new_tokens=int(max_tokens),
            do_sample=False,
        )
    
    # ê²°ê³¼ ë””ì½”ë”©
    response = processor.batch_decode(
        output_ids,
        skip_special_tokens=True
    )[0].strip()
    
    # íŒŒì¼ë¡œ ì €ì¥
    if save_to_file:
        # ë¹„ë””ì˜¤ íŒŒì¼ëª…ì—ì„œ í™•ì¥ìë¥¼ ì œê±°í•˜ê³  .txtë¡œ ë³€ê²½
        video_basename = os.path.basename(video_path)  # my_video.mp4
        video_name = os.path.splitext(video_basename)[0]  # my_video
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì • (outputs í´ë”)
        output_dir = "/workspace/outputs"
        os.makedirs(output_dir, exist_ok=True)
        
        # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        output_file = os.path.join(output_dir, f"{video_name}.txt")
        
        # í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(f"Video: {video_basename}\n")
                f.write(f"Analysis Date: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("=" * 80 + "\n\n")
                f.write(response)
                f.write("\n")
            
            print(f"âœ“ Summary saved to: {output_file}")
            response += f"\n\nğŸ“ Saved to: {output_file}"
        except Exception as e:
            print(f"Warning: Could not save to file: {str(e)}")
            response += f"\n\nâš ï¸ Could not save to file: {str(e)}"
    
    return response


def create_demo():
    """Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
    
    with gr.Blocks(title="VideoLLaMA3 Custom Demo") as demo:
        gr.Markdown("# ğŸ¥ VideoLLaMA3 Video Analysis")
        gr.Markdown("Upload a video and get detailed analysis with custom instructions")
        
        with gr.Row():
            with gr.Column(scale=1):
                # ì…ë ¥ ì˜ì—­
                video_input = gr.Video(
                    label="Upload Video",
                    height=300
                )
                
                with gr.Accordion("âš™ï¸ Advanced Settings", open=False):
                    fps_slider = gr.Slider(
                        minimum=0.5,
                        maximum=2.0,
                        value=1.0,
                        step=0.5,
                        label="FPS (frames per second sampling)",
                        info="Lower = fewer frames, faster processing"
                    )
                    
                    max_frames_slider = gr.Slider(
                        minimum=30,
                        maximum=180,
                        value=120,
                        step=10,
                        label="Max Frames",
                        info="Maximum number of frames to analyze"
                    )
                    
                    max_tokens_slider = gr.Slider(
                        minimum=256,
                        maximum=1024,
                        value=512,
                        step=256,
                        label="Max Output Tokens",
                        info="Higher = more detailed (but slower)"
                    )
                
                with gr.Accordion("âœï¸ Custom Instruction", open=True):
                    use_default = gr.Checkbox(
                        label="Use Default Detailed Analysis",
                        value=True,
                        info="Uncheck to use custom question below"
                    )
                    
                    custom_question = gr.Textbox(
                        label="Custom Question",
                        placeholder="e.g., What are the main activities in this video?",
                        lines=3,
                        interactive=True
                    )
                    
                    save_file = gr.Checkbox(
                        label="ğŸ’¾ Save summary to file",
                        value=True,
                        info="Save as {video_name}.txt in outputs folder"
                    )
                
                analyze_btn = gr.Button("ğŸš€ Analyze Video", variant="primary", size="lg")
            
            with gr.Column(scale=1):
                # ì¶œë ¥ ì˜ì—­
                output_text = gr.Textbox(
                    label="Analysis Result",
                    lines=20,
                    max_lines=30,
                    show_copy_button=True
                )
        
        # ì˜ˆì‹œ ì„¹ì…˜
        gr.Markdown("## ğŸ“ Example Questions")
        gr.Markdown("""
        - What are the main activities happening in this video?
        - Describe the setting and environment of this video.
        - What objects and people appear in this video?
        - Summarize the key events in chronological order.
        - What is the overall theme or purpose of this video?
        """)
        
        # ì´ë²¤íŠ¸ ì—°ê²°
        analyze_btn.click(
            fn=analyze_video,
            inputs=[
                video_input,
                fps_slider,
                max_frames_slider,
                max_tokens_slider,
                custom_question,
                use_default,
                save_file  # ì¶”ê°€
            ],
            outputs=output_text
        )
    
    return demo



if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument("--model-path", type=str, default="DAMO-NLP-SG/VideoLLaMA3-7B")
    parser.add_argument("--server-port", type=int, default=80)
    # parser.add_argument("--interface-port", "--interface_port", type=int, default=8080)
    parser.add_argument("--share", action="store_true", help="Create public link")
    
    args = parser.parse_args()
    
    # ëª¨ë¸ ì‚¬ì „ ë¡œë“œ (ì„ íƒì‚¬í•­)
    print("Pre-loading model...")
    load_model(args.model_path)
    
    # Gradio ì‹¤í–‰
    demo = create_demo()
    demo.launch(
        server_name="0.0.0.0",  # ëª¨ë“  ì¸í„°í˜ì´ìŠ¤ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥
        server_port=args.server_port,
        share=args.share,
        allowed_paths=["/tmp", "/workspace"]  # íŒŒì¼ ì ‘ê·¼ í—ˆìš© ê²½ë¡œ
    )